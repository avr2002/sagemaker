#!/bin/bash

set -ex

export AWS_PROFILE=sandbox
export AWS_REGION=us-east-1
export AWS_DEFAULT_REGION=${AWS_REGION}

# aws account id/hash used to make a unique, but consistent bucket name
export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --profile $AWS_PROFILE --query "Account" --output text)
export AWS_ACCOUNT_ID_HASH=$(echo -n "${AWS_ACCOUNT_ID}" | sha256sum | cut -c5-8)

export S3_BUCKET_NAME="ml-school-bucket-${AWS_ACCOUNT_ID_HASH}" # ml-school-bucket-6721

# REPOSITORY_NAME="processing-job"  # ECR repository name
# Source the .env file if it exists
[ -f .env ] && source .env

THIS_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"

# Data file path
DATA_FILE_PATH="$THIS_DIR/data/penguins.csv" # Path to the data file on your local machine
FILE_NAME="$(basename "$DATA_FILE_PATH")"
S3_FILE_PATH="penguins/data/$FILE_NAME"      # Path to the data file in the S3 bucket


##########################
# --- Task Functions --- #
##########################

function run-pipeline () {
    uv run pipeline.py
}


function cdk-bootstrap () {
    AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
    cdk bootstrap "aws://${AWS_ACCOUNT_ID}/${AWS_REGION}"
}

function cdk-deploy () {
    uv run -- cdk deploy --app 'python cdk_app.py' '*' --profile $AWS_PROFILE --region $AWS_REGION
}

function cdk-destroy () {
    uv run -- cdk destroy --app 'python cdk_app.py' '*' --profile $AWS_PROFILE --region $AWS_REGION
}


# Install Python dependencies into the currently activated venv
function install {
    # if uv is not installed, then update the commands as `python -m pip install --upgrade pip`
	uv run pip install --upgrade pip
	uv run pip install --editable "$THIS_DIR/[dev]"

	# python -m pip install --upgrade pip
	# python -m pip install --editable "$THIS_DIR/[dev]"

    # If using uv and you are getting pyyaml compilation error during installation then follow the below thread:
    # https://github.com/astral-sh/uv/issues/1455
    # This error doesn't occur when using the normal python command.
    # The error happend with python version 3.10.x [NOT SURE]
}


function run-docker {
    # Remove old AWS credentials
    remove-old-aws-credentials

    # Append new AWS credentials to .env
    aws configure export-credentials --profile "$AWS_PROFILE" --format env > .env-aws

    # Build the Docker image and push it to ECR
    # docker-build-image-and-push-to-ecr

    # Run the Docker container
    docker compose up --remove-orphans --build
}


function docker-build-image-and-push-to-ecr {
    set -ex

    local repository_name=$1
    local dockerfile_path=$2

    # Check if docker is running
    if ! docker info > /dev/null 2>&1; then
        echo "Error: Docker is not running."
        return 1
    fi

    # Get the AWS account ID
    # AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
    ECR_URI="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$repository_name:latest"

    # Build the Docker image
    if [ -d "$THIS_DIR/$dockerfile_path" ] || [ -f "$THIS_DIR/$dockerfile_path" ]; then
        docker build --tag $repository_name $THIS_DIR/$dockerfile_path
    else
        echo "Error: $dockerfile_path is not a directory or a file."
        return 1
    fi

    # Authenticate Docker to the ECR
    aws ecr get-login-password --region $AWS_REGION \
        | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com

    # Ensure that the repository exists
    aws ecr describe-repositories --repository-names "$repository_name" --region ${AWS_REGION} > /dev/null 2>&1 || \
    aws ecr create-repository --repository-name "${repository_name}" --region ${AWS_REGION} > /dev/null

    # Tag and push the Docker image to the ECR
    docker tag $repository_name:latest $ECR_URI
    docker push $ECR_URI
}


# Function to remove old AWS credentials from the .env file
function remove-old-aws-credentials {
    # Delete any lines that export AWS credentials
    sed -i '' '/^export AWS_ACCESS_KEY_ID/d' .env
    sed -i '' '/^export AWS_SECRET_ACCESS_KEY/d' .env
    sed -i '' '/^export AWS_SESSION_TOKEN/d' .env
    sed -i '' '/^export AWS_CREDENTIAL_EXPIRATION/d' .env

    # Ensure there is a new line at the end of the .env file if it's missing, so that the new credentials are on a new line
    if [ "$(tail -c 1 .env)" != "" ]; then
        echo "" >> .env
    fi
}


# run linting, formatting, and other static code quality tools
function lint {
	pre-commit run --all-files
}

# same as `lint` but with any special considerations for CI
function lint:ci {
	# We skip no-commit-to-branch since that blocks commits to `main`.
	# All merged PRs are commits to `main` so this must be disabled.
	SKIP=no-commit-to-branch pre-commit run --all-files
}

# remove all files generated by tests, builds, or operating this codebase
function clean {
	rm -rf dist build coverage.xml test-reports
	find . \
	  -type d \
	  \( \
		-name "*cache*" \
		-o -name "*.dist-info" \
		-o -name "*.egg-info" \
		-o -name "*htmlcov" \
        -o -name "cdk.out" \
	  \) \
	  -not -path "*env*/*" \
	  -exec rm -r {} + || true

	find . \
	  -type f \
	  -name "*.pyc" \
	  -not -path "*env/*" \
	  -exec rm {} +
}


# print all functions in this file
function help {
    echo "$0 <task> <args>"
    echo "Tasks:"
    compgen -A function | cat -n
}


TIMEFORMAT="Task completed in %3lR"
time ${@:-help}
